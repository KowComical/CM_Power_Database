{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fc5e74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, re, os,datetime,calendar,matplotlib.pyplot as plt\n",
    "################################备注########################################\n",
    "#df_cleaned 时间列 = ['datetime','date','year','month','month_date','weekday','hour']\n",
    "#df_simulated_hourly 时间列 = ['datetime','date','year','month','month_date','weekday','hour'] unit = ['Mwh']\n",
    "#df_simulated_daily 时间列 = ['date','year','month','month_date','weekday'] unit = ['Gwh']\n",
    "#df_simulated_monthly 时间列 = ['year','month'] unit = ['Gwh']\n",
    "############################function#########################################\n",
    "def write_pic(file_path, country):\n",
    "    iea = iea_data(country)\n",
    "    result = []\n",
    "    folder = os.listdir(file_path)\n",
    "    for dbtype in folder[::]:\n",
    "        if os.path.isfile(os.path.join(file_path,dbtype)):\n",
    "            folder.remove(dbtype)\n",
    "    for f in folder:\n",
    "        d_file_path = file_path+f+'\\\\'\n",
    "        file = os.listdir(d_file_path)\n",
    "        file_name = []\n",
    "        for dbtype in file:\n",
    "            if os.path.isfile(os.path.join(d_file_path,dbtype)):\n",
    "                file_name.append(dbtype)\n",
    "        file_name = [file_name[i] for i,x in enumerate(file_name) if x.find('monthly')!=-1]\n",
    "        df = pd.read_csv(d_file_path+file_name[0])\n",
    "        result.append(df)\n",
    "    df_all = pd.DataFrame(np.concatenate(result), columns = df.columns)\n",
    "    df_all['date'] = pd.to_datetime(df_all[['year', 'month']].assign(Day=1))#合并年月\n",
    "    iea['date'] = pd.to_datetime(iea[['year', 'month']].assign(Day=1))#合并年月\n",
    "    date_list = sorted(list(set(df_all['date']) & set(iea['date'])))\n",
    "\n",
    "    df_all = df_all.set_index('date').loc[date_list].reset_index()\n",
    "    iea = iea.set_index('date').loc[date_list].reset_index()\n",
    "\n",
    "    font_size = 25\n",
    "    plt.figure(figsize=(25, 25))\n",
    "    i = 1\n",
    "    for z in df_all.columns.tolist():\n",
    "        if z in iea.columns.tolist():\n",
    "            if z != 'year' and z != 'month' and z != 'date':\n",
    "                pic = plt.subplot(4,2, i)\n",
    "                pic.set_title ('[' + str(i) + ']'+ ' '+z, size = font_size)\n",
    "                i += 1\n",
    "                x = df_all['date']\n",
    "                y1 = df_all[z]\n",
    "                y2 = iea[z]\n",
    "                plt.plot(x,y1, color = 'red', label = 'simulated')\n",
    "                plt.plot(x,y2, label = 'iea')\n",
    "                #plt.tick_params(labelsize=font_size)\n",
    "                plt.xlabel('Year', size = font_size)\n",
    "                plt.ylabel('Emissions', size = font_size)\n",
    "                plt.rcParams.update({'font.size': 15})\n",
    "                pic.legend(loc = 0)\n",
    "                plt.tight_layout()\n",
    "    plt.savefig('D:\\\\Python\\\\Work\\\\朱碧青\\\\Image_Store\\\\2022\\\\02-25\\\\'+country+'.png')\n",
    "    \n",
    "def create_folder(file_path,Type): #建立需要的文件夹\n",
    "    out_path = file_path+Type+'\\\\'\n",
    "    if not os.path.exists(out_path): #如果有了文件夹的话就直接pass掉\n",
    "        os.mkdir(out_path)\n",
    "    return out_path\n",
    "def check_col(df,Type): #检查数据的现存列名是否一致 如果不一致就删掉多余的\n",
    "    df_col = df.columns.tolist()\n",
    "    if Type == 'hourly': #如果是simulated_hourly\n",
    "        r_col = ['unit','datetime', 'date','year','month','month_date','weekday','hour','coal','oil','gas','nuclear','hydro','wind','solar','other','fossil','low.carbon','total.prod','coal.perc','oil.perc','gas.perc','nuclear.perc','hydro.perc','wind.perc','solar.perc','other.perc','fossil.perc','low.carbon.perc']\n",
    "        df['unit'] = 'Mwh'\n",
    "    if Type == 'daily':\n",
    "        r_col = ['unit','date','year','month','month_date','weekday','coal','oil','gas','nuclear','hydro','wind','solar','other','fossil','low.carbon','total.prod','coal.perc','oil.perc','gas.perc','nuclear.perc','hydro.perc','wind.perc','solar.perc','other.perc','fossil.perc','low.carbon.perc']\n",
    "        df['unit'] = 'Gwh'\n",
    "    if Type == 'monthly':\n",
    "        r_col = ['unit','year','month','coal','oil','gas','nuclear','hydro','wind','solar','other','fossil','low.carbon','total.prod','coal.perc','oil.perc','gas.perc','nuclear.perc','hydro.perc','wind.perc','solar.perc','other.perc','fossil.perc','low.carbon.perc']\n",
    "        df['unit'] = 'Gwh'\n",
    "    df = df[r_col]\n",
    "    return df\n",
    "def time_b_a(x,which): #根据which 选择得到所选日期的前which天或者后which天\n",
    "    myday = datetime.datetime.strptime(x,'%Y-%m-%d')\n",
    "    delta = datetime.timedelta(days=which)\n",
    "    my_yestoday = myday + delta\n",
    "    my_yes_time = my_yestoday.strftime('%Y-%m-%d')\n",
    "    return my_yes_time    \n",
    "def time_info(df,date_name): #添加各种时间列\n",
    "    df[date_name] = pd.to_datetime(df[date_name])\n",
    "    df['year'] = df[date_name].dt.year\n",
    "    df['month'] = df[date_name].dt.month\n",
    "    df['month_date']  = df[date_name].dt.strftime('%m-%d')\n",
    "    df['weekday'] = df[date_name].dt.day_name()\n",
    "    df['hour'] = df[date_name].dt.hour\n",
    "    if date_name != 'date':\n",
    "        df['date'] = df[date_name].dt.strftime('%Y-%m-%d')\n",
    "def check_date(df,date_name,f): #检查现存时间缺失值并填充\n",
    "    df[date_name] = pd.to_datetime(df[date_name])\n",
    "    real_date = pd.date_range(start=min(df[date_name]),end = max(df[date_name]),freq = f).tolist()\n",
    "    df_date = df[date_name].drop_duplicates().tolist()\n",
    "    missing_date = list(set(real_date)-set(df_date))\n",
    "    for z in missing_date:\n",
    "        df = df.append([{date_name:z}], ignore_index=True)\n",
    "        df = df.sort_values(by = date_name).reset_index(drop = True)\n",
    "    time_info(df,date_name)\n",
    "    return df\n",
    "def insert_date(df,date_name,z):\n",
    "    df[date_name] = pd.to_datetime(df[date_name])\n",
    "    df = df.append([{date_name:z}], ignore_index=True)\n",
    "    df = df.sort_values(by = date_name).reset_index(drop = True)\n",
    "    return df\n",
    "def iea_data(j):\n",
    "    j = j.upper()\n",
    "    mon_path = 'D:\\\\Python\\\\Work\\\\朱碧青\\\\Code_Store\\\\数据库\\\\data\\\\#global_rf\\\\iea\\\\per_country\\\\'\n",
    "    df_mon = pd.read_csv(mon_path+j+'.csv').rename(columns = {'NaturalGas':'gas'})\n",
    "    df_mon.columns = df_mon.columns.map(lambda x:x.lower()) # 全小写\n",
    "    other_list = ['combustiblerenewables', 'geothermal','otherrenewables']\n",
    "    total_list = ['coal','gas','oil','nuclear','hydro','wind','solar','other']\n",
    "    all_list = total_list+['total.gen','year','month']\n",
    "    df_mon['other'] = df_mon[other_list].astype(float).sum(axis = 1)\n",
    "    df_mon['total.gen'] = df_mon[total_list].astype(float).sum(axis = 1)\n",
    "    df_mon = df_mon[all_list]\n",
    "    return df_mon\n",
    "#填充缺失值\n",
    "def fill_null(df,j,date_name,Type):\n",
    "    df_mon = iea_data(j)\n",
    "    filling_result = []\n",
    "    df_null = df[df.isna().any(axis=1)].reset_index(drop = True) #所有包含缺失值的行\n",
    "    df_not_null = df[~df.isna().any(axis=1)].reset_index(drop = True) #所有不包含缺失值的行\n",
    "    for x in df_null['year'].drop_duplicates().tolist(): #按年份循环\n",
    "        df_temp = df_null[df_null['year'] == x].reset_index(drop = True) #按年份赋值新的df\n",
    "        for y in df_temp['month'].drop_duplicates().tolist(): #新df中按月循环\n",
    "            df_temp_month = df_temp[df_temp['month'] == y].reset_index(drop = True) #按月份赋值新的df\n",
    "            month_date = calendar.monthrange(x,y)[1] #计算当月天数\n",
    "            for z in df_mon.columns.tolist(): \n",
    "                if df_mon[z].dtype == float and z != 'total.gen': #如果这一列类型是float并且不为total时\n",
    "                    try:#如果这一列类型是float并且不为total时\n",
    "                        df_temp_month[z] = df_mon[(df_mon['year'] == x) & (df_mon['month'] == y)][z].tolist()[0]/month_date\n",
    "                    except:\n",
    "                        df_temp_month[z] = df_mon[(df_mon['year'] == x-1) & (df_mon['month'] == y)][z].tolist()[0]/month_date\n",
    "            filling_result.append(df_temp_month)\n",
    "    df_missing = pd.DataFrame(np.concatenate(filling_result), columns = df_temp_month.columns)\n",
    "    df = pd.concat([df_missing,df_not_null])\n",
    "    df = df.sort_values(by = date_name).reset_index(drop = True)\n",
    "    total_proc(df, unit = True)\n",
    "    df = check_col(df,Type)\n",
    "    return df\n",
    "def total_proc(df, unit = True): #处理数据\n",
    "    fossil_list = ['coal','gas','oil']\n",
    "    carbon_list = ['nuclear','hydro','wind','solar','other']\n",
    "    perc_list = ['fossil','low.carbon']\n",
    "    df[fossil_list] = df[fossil_list].astype(float)\n",
    "    df[carbon_list] = df[carbon_list].astype(float)\n",
    "    df['fossil'] = df[fossil_list].astype(float).sum(axis = 1)\n",
    "    df['low.carbon'] = df[carbon_list].astype(float).sum(axis = 1)\n",
    "    df['total.prod'] = df[perc_list].astype(float).sum(axis = 1)\n",
    "    if unit == True:\n",
    "        for z in df.columns.tolist():\n",
    "            if df[z].dtype == float:\n",
    "                df[z] = df[z]/1000\n",
    "    for y in df.columns.tolist():\n",
    "        if df[y].dtype == float:\n",
    "            if y != 'total.prod' and 'perc' not in y:\n",
    "                df[y+'.perc'] = df[y]/df['total.prod']          \n",
    "    df['unit'] = 'Gwh' #补充单位\n",
    "    \n",
    "def agg(df,date_name,path,Type,name,folder, unit): #输出\n",
    "    time_info(df,date_name)\n",
    "    total_proc(df, unit)\n",
    "    df = check_col(df,Type)\n",
    "    if folder == True:\n",
    "        out_path = create_folder(path,Type)\n",
    "        out_file = out_path+name\n",
    "    else:\n",
    "        out_file = path+name\n",
    "    df.to_csv(out_file, index = False, encoding = 'utf_8_sig')\n",
    "############################################################################################################################################\n",
    "file_path = 'D:\\\\Python\\\\Work\\\\朱碧青\\\\Code_Store\\\\数据库\\\\data\\\\europe\\\\eu27_uk\\\\'\n",
    "in_path_entsoe = file_path+'raw\\\\entsoe\\\\'\n",
    "in_path_bmrs = file_path+'raw\\\\uk-BMRS\\\\'\n",
    "\n",
    "out_path_cleaned  = create_folder(file_path,'cleaned')\n",
    "out_path_simulated = create_folder(file_path,'simulated')\n",
    "################################################################################################################################\n",
    "coal_list = ['Fossil Brown coal/Lignite  - Actual Aggregated [MW]',\n",
    "                         'Fossil Coal-derived gas  - Actual Aggregated [MW]',\n",
    "                         'Fossil Hard coal  - Actual Aggregated [MW]',\n",
    "                         'Fossil Peat  - Actual Aggregated [MW]']\n",
    "gas_list = ['Fossil Gas  - Actual Aggregated [MW]']\n",
    "oil_list = ['Fossil Oil  - Actual Aggregated [MW]',\n",
    "                        'Fossil Oil shale  - Actual Aggregated [MW]']\n",
    "other_list = ['Biomass  - Actual Aggregated [MW]',\n",
    "                          'Geothermal  - Actual Aggregated [MW]',\n",
    "                         'Other  - Actual Aggregated [MW]',\n",
    "                         'Other renewable  - Actual Aggregated [MW]',\n",
    "                         'Waste  - Actual Aggregated [MW]']\n",
    "hydro_list = ['Hydro Pumped Storage  - Actual Aggregated [MW]',\n",
    "                         'Hydro Pumped Storage  - Actual Consumption [MW]',\n",
    "                         'Hydro Run-of-river and poundage  - Actual Aggregated [MW]',\n",
    "                         'Hydro Water Reservoir  - Actual Aggregated [MW]']\n",
    "wind_list = ['Wind Offshore  - Actual Aggregated [MW]',\n",
    "                        'Wind Onshore  - Actual Aggregated [MW]']\n",
    "#################################################################################################################\n",
    "file = os.listdir(in_path_entsoe)\n",
    "file_name = []\n",
    "for dbtype in file:\n",
    "    if os.path.isfile(os.path.join(in_path_entsoe,dbtype)):\n",
    "        file_name.append(dbtype)\n",
    "#################################################raw-cleaned-simulated_bmrs##########################################\n",
    "#bmrs\n",
    "df_bmrs = pd.read_csv(in_path_bmrs+'UK_BMRS_Hourly.csv')\n",
    "time_info(df_bmrs,'startTimeOfHalfHrPeriod')\n",
    "for y in df_bmrs['year'].drop_duplicates().tolist():\n",
    "    df_bmrs_cleaned_yearly = df_bmrs[df_bmrs['year'] == y].reset_index(drop = True)\n",
    "    df_hourly = df_bmrs_cleaned_yearly.copy()\n",
    "    out_path_cleaned_yearly = create_folder(out_path_cleaned,str(y))\n",
    "    df_bmrs_cleaned_yearly.to_csv(out_path_cleaned_yearly+'United_Kingdom_BMRS.csv', index = False, encoding = 'utf_8_sig')\n",
    "\n",
    "df_bmrs['gas'] = df_bmrs['ccgt']+df_bmrs['ocgt']\n",
    "df_bmrs['hydro'] = df_bmrs['ps']+df_bmrs['npshyd']\n",
    "df_bmrs['other'] = df_bmrs['biomass']+df_bmrs['other']\n",
    "df_bmrs['solar'] = 0 #存疑\n",
    "\n",
    "df_bmrs['datetime'] = pd.to_datetime(df_bmrs['startTimeOfHalfHrPeriod']) + pd.to_timedelta((df_bmrs['settlementPeriod']/2-0.5), unit='h')\n",
    "\n",
    "df_bmrs = df_bmrs.set_index('datetime').resample('H').mean().reset_index()\n",
    "time_info(df_bmrs,'datetime')\n",
    "for y in df_bmrs['year'].drop_duplicates().tolist():\n",
    "    #simulated准备工作\n",
    "    df_bmrs_hourly = df_bmrs[df_bmrs['year'] == y].reset_index(drop = True)\n",
    "    df_bmrs_daily = df_bmrs_hourly.copy()\n",
    "    df_bmrs_monthly = df_bmrs_hourly.copy()\n",
    "    out_path_simulated_yearly = create_folder(out_path_simulated,str(y))\n",
    "    out_path_simulated_yearly_per = create_folder(out_path_simulated_yearly,'per_country')\n",
    "#hourly\n",
    "    agg(df_bmrs_hourly,'datetime',out_path_simulated_yearly_per,'hourly',name = 'United_Kingdom_BMRS.csv', folder = True, unit = False)\n",
    "#daily\n",
    "    df_bmrs_daily = df_bmrs_daily.set_index('datetime').resample('d').sum().reset_index()\n",
    "    agg(df_bmrs_daily,'datetime',out_path_simulated_yearly_per,'daily','United_Kingdom_BMRS.csv', folder = True, unit = True)\n",
    "#monthly\n",
    "    df_bmrs_monthly = df_bmrs_monthly.set_index('datetime').resample('m').sum().reset_index()\n",
    "    agg(df_bmrs_monthly,'datetime',out_path_simulated_yearly_per,'monthly','United_Kingdom_BMRS.csv', folder = True, unit = True)\n",
    "#########################################entose-raw-cleaned-simulated#############################################\n",
    "for x in file_name:\n",
    "    df_cleaned = pd.read_csv(in_path_entsoe+x).rename(columns = {'MTU':'datetime'})\n",
    "    time_info(df_cleaned,'datetime')\n",
    "    for y in df_cleaned['year'].drop_duplicates().tolist():\n",
    "        df_cleaned_yearly = df_cleaned[df_cleaned['year'] == y].reset_index(drop = True)\n",
    "        df_hourly = df_cleaned_yearly.copy()\n",
    "        out_path_cleaned_yearly = create_folder(out_path_cleaned,str(y))\n",
    "        df_cleaned_yearly.to_csv(out_path_cleaned_yearly+x, index = False, encoding = 'utf_8_sig')   \n",
    "#######simulated 准备工作\n",
    "        df_hourly['coal'] = df_hourly[coal_list].astype(float).sum(axis = 1)\n",
    "        df_hourly['oil'] = df_hourly[oil_list].astype(float).sum(axis = 1)\n",
    "        df_hourly['gas'] = df_hourly[gas_list].astype(float).sum(axis = 1)\n",
    "        df_hourly['nuclear'] = df_hourly['Nuclear  - Actual Aggregated [MW]']\n",
    "        df_hourly['hydro'] = df_hourly[hydro_list].astype(float).sum(axis = 1)\n",
    "        df_hourly['wind'] = df_hourly[wind_list].astype(float).sum(axis = 1)\n",
    "        df_hourly['solar'] = df_hourly['Solar  - Actual Aggregated [MW]']\n",
    "        df_hourly['other'] = df_hourly[other_list].astype(float).sum(axis = 1)\n",
    "\n",
    "        df_col = df_hourly.columns.tolist()\n",
    "        all_list =  [df_col[i] for i,x in enumerate(df_col) if not x.find('MW')!=-1]\n",
    "        df_hourly = df_hourly[all_list]\n",
    "        df_daily = df_hourly.copy()\n",
    "        df_monthly = df_hourly.copy()\n",
    "        out_path_simulated_yearly = create_folder(out_path_simulated,str(y))\n",
    "        out_path_simulated_yearly_per = create_folder(out_path_simulated_yearly,'per_country')\n",
    "#####hourly\n",
    "        agg(df_hourly,'datetime',out_path_simulated_yearly_per,'hourly',x, folder = True, unit = False)\n",
    "#####daily\n",
    "        df_daily = df_daily.set_index('datetime').resample('d').sum().reset_index()\n",
    "        agg(df_daily,'datetime',out_path_simulated_yearly_per,'daily',x, folder = True, unit = True)\n",
    "#####monthly\n",
    "        df_monthly = df_monthly.set_index('datetime').resample('m').sum().reset_index()\n",
    "        agg(df_monthly,'datetime',out_path_simulated_yearly_per,'monthly',x, folder = True, unit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "889faec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.eu()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
