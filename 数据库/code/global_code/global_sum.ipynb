{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bd5b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, re, os\n",
    "def check_col(df,Type): #检查数据的现存列名是否一致 如果不一致就删掉多余的\n",
    "    df_col = df.columns.tolist()\n",
    "    if Type == 'hourly': #如果是simulated_hourly\n",
    "        r_col = ['unit','datetime', 'date','year','month','month_date','weekday','hour','coal','oil','gas','nuclear','hydro','wind','solar','other','fossil','low.carbon','total.prod','coal.perc','oil.perc','gas.perc','nuclear.perc','hydro.perc','wind.perc','solar.perc','other.perc','fossil.perc','low.carbon.perc']\n",
    "        df['unit'] = 'Mwh'\n",
    "    if Type == 'daily':\n",
    "        r_col = ['unit','date','year','month','month_date','weekday','coal','oil','gas','nuclear','hydro','wind','solar','other','fossil','low.carbon','total.prod','coal.perc','oil.perc','gas.perc','nuclear.perc','hydro.perc','wind.perc','solar.perc','other.perc','fossil.perc','low.carbon.perc']\n",
    "        df['unit'] = 'Gwh'\n",
    "    if Type == 'monthly':\n",
    "        r_col = ['unit','year','month','coal','oil','gas','nuclear','hydro','wind','solar','other','fossil','low.carbon','total.prod','coal.perc','oil.perc','gas.perc','nuclear.perc','hydro.perc','wind.perc','solar.perc','other.perc','fossil.perc','low.carbon.perc']\n",
    "        df['unit'] = 'Gwh'\n",
    "    df = df[r_col]\n",
    "    return df\n",
    "\n",
    "def time_info(df,date_name): #添加各种时间列\n",
    "    df[date_name] = pd.to_datetime(df[date_name])\n",
    "    df['year'] = df[date_name].dt.year\n",
    "    df['month'] = df[date_name].dt.month\n",
    "    df['month_date']  = df[date_name].dt.strftime('%m-%d')\n",
    "    df['weekday'] = df[date_name].dt.day_name()\n",
    "    if date_name != 'date':\n",
    "        df['date'] = df[date_name].dt.strftime('%Y-%m-%d')\n",
    "        df['hour'] = df[date_name].dt.hour\n",
    "\n",
    "file_path = 'K:\\\\Github\\\\GlobalPowerUpdate-Kow\\\\数据库\\\\data\\\\'\n",
    "file_name = []\n",
    "for parent, dirnames, filenames in os.walk(file_path):\n",
    "    for fn in filenames:\n",
    "        file_name.append(os.path.join(parent, fn))\n",
    "file_name = [file_name[i] for i,x in enumerate(file_name) if x.find('simulated')!=-1]\n",
    "file_name = [file_name[i] for i,x in enumerate(file_name) if x.find('daily')!=-1]\n",
    "file_name_no = [file_name[i] for i,x in enumerate(file_name) if not x.find('eu27_uk')!=-1]\n",
    "file_name_eu = [file_name[i] for i,x in enumerate(file_name) if x.find('eu27_uk')!=-1]\n",
    "file_name_eu = [file_name_eu[i] for i,x in enumerate(file_name_eu) if not x.find('United Kingdom')!=-1]\n",
    "\n",
    "#提取国家名\n",
    "title = re.compile(r'data.*?\\\\.*?\\\\(?P<name>.*?)\\\\simulated', re.S)\n",
    "country_name_no = []\n",
    "for f in file_name_no:\n",
    "    result = title.finditer(f) \n",
    "    for it in result:\n",
    "        country_name_no.append(it.group('name'))\n",
    "        \n",
    "#欧盟国家\n",
    "title = re.compile(r'daily\\\\(?P<name>.*?).csv', re.S)\n",
    "country_name_eu = []\n",
    "for f in file_name_eu:\n",
    "    result = title.finditer(f) \n",
    "    for it in result:\n",
    "        country_name_eu.append(it.group('name'))\n",
    "\n",
    "result_no = []\n",
    "for f,c in zip(file_name_no,country_name_no):\n",
    "    if c!='russia':\n",
    "        df_temp = pd.read_csv(f)\n",
    "        time_info(df_temp,'date')\n",
    "        df_temp = check_col(df_temp,'daily')\n",
    "        df_temp['country'] = c.capitalize()\n",
    "        result_no.append(df_temp)\n",
    "df_no = pd.DataFrame(np.concatenate(result_no), columns = df_temp.columns)\n",
    "\n",
    "result_eu = []\n",
    "for f,c in zip(file_name_eu,country_name_eu):\n",
    "    df_temp = pd.read_csv(f)\n",
    "    df_temp['country'] = c.capitalize()\n",
    "    result_eu.append(df_temp)\n",
    "df_eu = pd.DataFrame(np.concatenate(result_eu), columns = df_temp.columns)\n",
    "df_all = pd.concat([df_no,df_eu]).reset_index(drop = True)\n",
    "\n",
    "result_eu_all = []\n",
    "for f,c in zip(file_name_eu,country_name_eu):\n",
    "    df_temp = pd.read_csv(f)\n",
    "    df_temp['country'] = 'EU27&UK'\n",
    "    result_eu_all.append(df_temp)\n",
    "df_eu_all = pd.DataFrame(np.concatenate(result_eu_all), columns = df_temp.columns)\n",
    "df_eu_all = df_eu_all.groupby(['unit','date','year','month','month_date','weekday','country']).sum().reset_index()\n",
    "df_all = pd.concat([df_all,df_eu_all]).reset_index(drop = True)\n",
    "\n",
    "#russia\n",
    "file_name_russia = [file_name_no[i] for i,x in enumerate(file_name_no) if x.find('russia')!=-1]\n",
    "df_russia = pd.concat([pd.read_csv(f) for f in file_name_russia]).drop(columns = ['P_BS','renewables','P_BS.perc','renewables.perc'])\n",
    "df_russia['country'] = 'Russia'\n",
    "\n",
    "df_all = pd.concat([df_all,df_russia]).reset_index(drop = True)\n",
    "for x in df_all.columns.tolist():\n",
    "    try:\n",
    "        df_all[x] =df_all[x].astype(float) \n",
    "    except:\n",
    "        pass\n",
    "time_info(df_all,'date')\n",
    "df_all = df_all[(df_all['year'] >=2019) & (df_all['year'] <=2021)].reset_index(drop = True)\n",
    "df_all = df_all.set_index(['unit','date','year','month','month_date','weekday','country']).stack().reset_index().rename(columns={'level_7':'Type', 0:'Value'})\n",
    "df_all = df_all[df_all['Type'].isin(['coal','gas','oil','nuclear','hydro','solar','wind','other'])].reset_index(drop = True)\n",
    "df_all['country'] = df_all['country'].str.replace('United_kingdom_bmrs','UK')\n",
    "df_all['country'] = df_all['country'].str.replace('Bosnia and Herz','Bosnia & Herz')\n",
    "df_all['country'] = df_all['country'].str.replace('Us','United States')\n",
    "df_all.to_csv(file_path+'global\\\\global.csv', index = False, encoding = 'utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63b5c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['date'] = pd.to_datetime(df_all['date'])\n",
    "\n",
    "df_all = df_all.drop(columns = ['weekday','month','unit'])\n",
    "index_list = ['month_date','country','Type']\n",
    "df_2019 = df_all[df_all['year']==2019].set_index(index_list)\n",
    "df_rest = df_all[df_all['year']!=2019].set_index(index_list)\n",
    "\n",
    "df_relative = (df_rest - df_2019).reset_index().dropna().drop(columns = ['date'])\n",
    "df_relative['year'] += 2019\n",
    "df_relative['year'] = df_relative['year'].astype(int)\n",
    "df_relative['date'] = df_relative['year'].astype(str)+'-'+df_relative['month_date'].astype(str)\n",
    "df_relative['date'] = pd.to_datetime(df_relative['date'])\n",
    "df_relative['month'] = df_relative['date'].dt.month\n",
    "df_relative.to_csv(file_path+'global\\\\global_relative.csv', index = False, encoding = 'utf_8_sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
